{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/Users/fitsl/Documents/Programming/UVM Programming Classes/Data Science I/Project'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def find_repo_root(start_path):\n",
    "    current_path = os.path.abspath(start_path)\n",
    "    \n",
    "    while True:\n",
    "        # Check for the existence of the .git directory or other indicators\n",
    "        if os.path.isdir(os.path.join(current_path, '.git')) or \\\n",
    "           os.path.isfile(os.path.join(current_path, 'README.md')):\n",
    "            current_path = current_path.replace('\\\\', '/')\n",
    "            return current_path\n",
    "        \n",
    "        parent_path = os.path.dirname(current_path)\n",
    "        \n",
    "        # Stop if we reach the root directory\n",
    "        if parent_path == current_path:\n",
    "            break\n",
    "        \n",
    "        current_path = parent_path\n",
    "\n",
    "    return None  # Return None if not found\n",
    "\n",
    "root = find_repo_root(os.getcwd())\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, analyze, create categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(f\"{root}/Data/Storm events/events_db_chunk_1.parquet\")\n",
    "df2 = pd.read_parquet(f\"{root}/Data/Storm events/events_db_chunk_2.parquet\")\n",
    "df3 = pd.read_parquet(f\"{root}/Data/Storm events/events_db_chunk_3.parquet\")\n",
    "df4 = pd.read_parquet(f\"{root}/Data/Storm events/events_db_chunk_4.parquet\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df['State FIPS'] = df['State FIPS'].apply(lambda x: f\"{int(x):02d}\")\n",
    "df['County/Zone FIPS'] = df['County/Zone FIPS'].apply(lambda x: f\"{int(x):03d}\")\n",
    "df['FIPS'] = df['State FIPS'] + df['County/Zone FIPS']\n",
    "df = df[df['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Property Damage'].value_counts()\n",
    "def convert_to_number(value):\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    value = value.strip().lower()\n",
    "    if value == 'k':\n",
    "        return 1000\n",
    "    elif value.endswith('k'):\n",
    "        return int(float(value[:-1]) * 1000)\n",
    "    elif value.endswith('m'):\n",
    "        return int(float(value[:-1]) * 1000000)\n",
    "    elif value.endswith('h'):\n",
    "        return int(float(value[:-1]) * 100)\n",
    "    elif value.endswith('b'):\n",
    "        return int(float(value[:-1]) * 1000000000)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def fk_log10(num):\n",
    "    if num == 0: return 0\n",
    "    else: return np.log10(num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property_num'] = df['Property Damage'].map(lambda x : convert_to_number(x))\n",
    "df['deaths'] = df['Direct Deaths'] + df['Indirect Deaths']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_num\n",
       "0         989218\n",
       "5000       38703\n",
       "1000       36127\n",
       "10000      32810\n",
       "2000       25898\n",
       "           ...  \n",
       "933000         1\n",
       "469000         1\n",
       "97500          1\n",
       "4600           1\n",
       "489000         1\n",
       "Name: count, Length: 2002, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['property_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.rename(columns={\n",
    "        \"State FIPS\" : \"STATE_FIPS\",\n",
    "        \"County/Zone FIPS\" : \"COUNTY_FIPS\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OBJECTID', 'State', 'Month', 'Event Type', 'Begin Date Time',\n",
      "       'Property Damage', 'Begin Lat', 'Begin Lon', 'Episode Narrative',\n",
      "       'Event Narrative', 'Lat/Lon Known', 'STATE_FIPS', 'Year', 'COUNTY_FIPS',\n",
      "       'County/Zone Type', 'Event ID', 'Direct Injuries', 'Indirect Injuries',\n",
      "       'Indirect Deaths', 'Direct Deaths', 'Episode ID', 'Source',\n",
      "       'Data Source', 'Tornado F Scale', 'County/Zone Name',\n",
      "       'Total Injuries and Deaths', 'x', 'y', 'FIPS', 'property_num',\n",
      "       'deaths'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['STATE_FIPS', 'COUNTY_FIPS', 'Year', 'County/Zone Name']).agg(\n",
    "    deaths=('deaths', 'sum' ),\n",
    "    property_damage=('property_num', 'sum')\n",
    ")\n",
    "df_agg.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>Year</th>\n",
       "      <th>County/Zone Name</th>\n",
       "      <th>deaths</th>\n",
       "      <th>property_damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48459</th>\n",
       "      <td>22</td>\n",
       "      <td>062</td>\n",
       "      <td>2005</td>\n",
       "      <td>ORLEANS</td>\n",
       "      <td>638</td>\n",
       "      <td>21481570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>06</td>\n",
       "      <td>066</td>\n",
       "      <td>2018</td>\n",
       "      <td>NORTHEAST FOOTHILLS/SACRAMENTO VALLEY</td>\n",
       "      <td>86</td>\n",
       "      <td>17000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115029</th>\n",
       "      <td>48</td>\n",
       "      <td>201</td>\n",
       "      <td>2017</td>\n",
       "      <td>HARRIS</td>\n",
       "      <td>39</td>\n",
       "      <td>10001921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114172</th>\n",
       "      <td>48</td>\n",
       "      <td>167</td>\n",
       "      <td>2017</td>\n",
       "      <td>GALVESTON</td>\n",
       "      <td>6</td>\n",
       "      <td>10000395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16119</th>\n",
       "      <td>12</td>\n",
       "      <td>068</td>\n",
       "      <td>2005</td>\n",
       "      <td>COASTAL PALM BEACH</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139880</th>\n",
       "      <td>99</td>\n",
       "      <td>145</td>\n",
       "      <td>2010</td>\n",
       "      <td>VEGA BAJA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139879</th>\n",
       "      <td>99</td>\n",
       "      <td>145</td>\n",
       "      <td>2009</td>\n",
       "      <td>VEGA BAJA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139878</th>\n",
       "      <td>99</td>\n",
       "      <td>143</td>\n",
       "      <td>2019</td>\n",
       "      <td>VEGA ALTA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139877</th>\n",
       "      <td>99</td>\n",
       "      <td>143</td>\n",
       "      <td>2018</td>\n",
       "      <td>VEGA ALTA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139892</th>\n",
       "      <td>99</td>\n",
       "      <td>149</td>\n",
       "      <td>2014</td>\n",
       "      <td>VILLALBA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139913 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATE_FIPS COUNTY_FIPS  Year                       County/Zone Name  \\\n",
       "48459          22         062  2005                                ORLEANS   \n",
       "9480           06         066  2018  NORTHEAST FOOTHILLS/SACRAMENTO VALLEY   \n",
       "115029         48         201  2017                                 HARRIS   \n",
       "114172         48         167  2017                              GALVESTON   \n",
       "16119          12         068  2005                     COASTAL PALM BEACH   \n",
       "...           ...         ...   ...                                    ...   \n",
       "139880         99         145  2010                              VEGA BAJA   \n",
       "139879         99         145  2009                              VEGA BAJA   \n",
       "139878         99         143  2019                              VEGA ALTA   \n",
       "139877         99         143  2018                              VEGA ALTA   \n",
       "139892         99         149  2014                               VILLALBA   \n",
       "\n",
       "        deaths  property_damage  \n",
       "48459      638      21481570000  \n",
       "9480        86      17000000000  \n",
       "115029      39      10001921000  \n",
       "114172       6      10000395500  \n",
       "16119        1      10000000000  \n",
       "...        ...              ...  \n",
       "139880       0                0  \n",
       "139879       0                0  \n",
       "139878       0                0  \n",
       "139877       0                0  \n",
       "139892       0                0  \n",
       "\n",
       "[139913 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.sort_values(by='property_damage', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_df = pd.read_csv(\n",
    "    f\"{root}/Data/Census/5_year_summary.csv\",\n",
    "    dtype= {\n",
    "        'county': str,\n",
    "        'state': str\n",
    "    })\n",
    "soc_df.rename(columns={\n",
    "    'state' : 'STATE_FIPS',\n",
    "    'county' : 'COUNTY_FIPS'}, \n",
    "    inplace=True)\n",
    "\n",
    "soc_df.drop(columns=[\n",
    "    'Unnamed: 0', ],\n",
    "    inplace=True)\n",
    "soc_df = soc_df\n",
    "\n",
    "\n",
    "soc_df = soc_df[['STATE_FIPS', 'COUNTY_FIPS',\n",
    "       'start_year', 'end_year', \n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>2006</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>2007</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>2008</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>2009</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32199</th>\n",
       "      <td>46</td>\n",
       "      <td>137</td>\n",
       "      <td>2011</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32200</th>\n",
       "      <td>46</td>\n",
       "      <td>137</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32201</th>\n",
       "      <td>46</td>\n",
       "      <td>137</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32202</th>\n",
       "      <td>46</td>\n",
       "      <td>137</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32203</th>\n",
       "      <td>46</td>\n",
       "      <td>137</td>\n",
       "      <td>2015</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32204 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATE_FIPS COUNTY_FIPS  start_year  end_year\n",
       "0             45         001        2006      2010\n",
       "1             45         001        2007      2011\n",
       "2             45         001        2008      2012\n",
       "3             45         001        2009      2013\n",
       "4             45         001        2010      2014\n",
       "...          ...         ...         ...       ...\n",
       "32199         46         137        2011      2015\n",
       "32200         46         137        2012      2016\n",
       "32201         46         137        2013      2017\n",
       "32202         46         137        2014      2018\n",
       "32203         46         137        2015      2019\n",
       "\n",
       "[32204 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n",
      "[(2005, 2009), (2006, 2010), (2007, 2011), (2008, 2012), (2009, 2013), (2010, 2014), (2011, 2015), (2012, 2016), (2013, 2017), (2014, 2018), (2015, 2019), (2016, 2020)]\n"
     ]
    }
   ],
   "source": [
    "periods = {}\n",
    "\n",
    "num_periods = [(i, i+4) for i in range(2005, 2017)]\n",
    "str_periods = [(str(i), str(i+4)) for i in range(2005, 2017)]\n",
    "\n",
    "period_ranges_exclusive = [] \n",
    "period_ranges_inclusive = []\n",
    "\n",
    "for period in num_periods:\n",
    "    year = period[0]\n",
    "    floor_2k = (2000, year)\n",
    "    floor_3 =  (max(year - 3, 2000), year)\n",
    "    floor_5=  (max(year - 5, 2000), year)\n",
    "    floor_10= (max(year - 10, 2000), year)\n",
    "    period_ranges_exclusive.append((floor_2k, floor_3, floor_5, floor_10))\n",
    "\n",
    "\n",
    "    end_year = period[1]\n",
    "    floor_2k = (2000, end_year)\n",
    "    floor_3 =  (max(year - 3, 2000), end_year)\n",
    "    floor_5=  (max(year - 5, 2000), end_year)\n",
    "    floor_10= (max(year - 10, 2000), end_year)\n",
    "    period_ranges_inclusive.append((floor_2k, floor_3, floor_5, floor_10))\n",
    "    print(num_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start, end 2005 2009\n",
      "start, end 2006 2010\n",
      "start, end 2007 2011\n",
      "start, end 2008 2012\n",
      "start, end 2009 2013\n",
      "start, end 2010 2014\n",
      "start, end 2011 2015\n",
      "start, end 2012 2016\n",
      "start, end 2013 2017\n",
      "start, end 2014 2018\n",
      "start, end 2015 2019\n",
      "start, end 2016 2020\n"
     ]
    }
   ],
   "source": [
    "table_form_events = df_agg.copy()\n",
    "\n",
    "for i, (start, end) in enumerate(str_periods):\n",
    "    print(\"start, end\", start, end)\n",
    "    inputpath = f\"{root}/Data/County/Summed_clean/summed_{start}_{end}.csv\"\n",
    "    folder = \"/Data/County/County_sum_with_StormEvents_Climate\"\n",
    "    county_data = pd.read_csv(inputpath, dtype={\n",
    "        \"STATE_FIPS\" : \"str\",\n",
    "        \"COUNTY_FIPS\" :  \"str\"\n",
    "    })\n",
    "\n",
    "    def period_namer(i):\n",
    "        if i == 0: return(\"From_2000\")\n",
    "        elif i == 1: return(\"Minus_3\")\n",
    "        elif i == 2: return(\"Minus_5\")\n",
    "        elif i == 3: return(\"Minus_10\")\n",
    "        else:\n",
    "            raise(\"too many periods in period, bro\")\n",
    "        \n",
    "\n",
    "    def group_period(df):\n",
    "        result = (\n",
    "        df.groupby(['STATE_FIPS', 'COUNTY_FIPS'])\n",
    "        .agg(\n",
    "            Population=('Population', 'mean'),\n",
    "            Inflow_pc=('Inflow_pc', 'mean'),\n",
    "            Inflow_gross=('Inflow_gross', 'mean'),\n",
    "            Outflow_pc=('Outflow_pc', 'mean'),\n",
    "            Outflow_gross=('Outflow_gross', 'mean'),\n",
    "            deaths=('deaths', 'sum' ),\n",
    "            property_damage=('property_damage', 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "        )\n",
    "        return result\n",
    "\n",
    "\n",
    "    #create data frames for all the sub-versions\n",
    "    for x, (period_begin, period_end) in enumerate(period_ranges_exclusive[i]):\n",
    "        # print(\"\\n\")\n",
    "        subfolder = period_namer(x)\n",
    "        # print(x, period_begin, period_end)\n",
    "        # print(int(start)-4, int(start))\n",
    "        \n",
    "        soc_df_time = soc_df[(soc_df['start_year'] == int(start)) & (soc_df['end_year'] == int(end))].copy()\n",
    "        # print(soc_df_time[['start_year', 'end_year']].head())\n",
    "\n",
    "        time_span_merged = pd.merge(\n",
    "            county_data,\n",
    "            table_form_events[table_form_events['Year'].isin(range(period_begin, period_end+1))],\n",
    "            on=['STATE_FIPS', 'COUNTY_FIPS']\n",
    "        )\n",
    "\n",
    "\n",
    "        time_span_merged = group_period(time_span_merged)\n",
    "        time_span_merged = pd.merge(\n",
    "            left=time_span_merged,\n",
    "            right=soc_df_time,\n",
    "            on=['STATE_FIPS', 'COUNTY_FIPS'],\n",
    "            how='left'\n",
    "        )\n",
    "        save_path = f\"{root}{folder}/Exclusive/{subfolder}/exclusive_merge_countysum_storm_{period_begin}_{period_end}.csv\"\n",
    "        time_span_merged.to_csv(save_path, index=False)\n",
    "\n",
    "    for x, (period_begin, period_end) in enumerate(period_ranges_inclusive[i]):\n",
    "        subfolder = period_namer(x)\n",
    "        soc_df_time = soc_df[(soc_df['start_year'] == int(start)) \n",
    "                             & (soc_df['end_year'] == int(end))].copy()\n",
    "        \n",
    "        time_span_merged = pd.merge(\n",
    "            county_data,\n",
    "            table_form_events[table_form_events['Year'].isin(range(period_begin, period_end+1))],\n",
    "            on=['STATE_FIPS', 'COUNTY_FIPS']\n",
    "        )\n",
    "        time_span_merged = group_period(time_span_merged)\n",
    "        time_span_merged = pd.merge(\n",
    "            left=time_span_merged,\n",
    "            right=soc_df_time,\n",
    "            on=['STATE_FIPS', 'COUNTY_FIPS'],\n",
    "            how='left'\n",
    "        )\n",
    "        save_path = f\"{root}{folder}/Inclusive/{subfolder}/inclusive_merge_countysum_storm_{period_begin}_{period_end}.csv\"\n",
    "        time_span_merged.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
